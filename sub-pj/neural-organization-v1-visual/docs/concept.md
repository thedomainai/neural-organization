### AX Company Architecture v1.0

~記憶を持ち、戦略に基づいて動き、人と共に学ぶ組織~

### 1. 入力層（Internal Input）

外部センシングを除外したため、ここでの入力は「社内の事実」に集中します。

- **定性データ:** 会議ログ、チャット、ドキュメント
- **定量データ:** KPI数値、財務データ、タスク進捗
- **人間からの指示:** 「このプロジェクトを始めて」といったトリガー

### 2. 中央記憶層（Corporate Memory）

ここがこのアーキテクチャの核です。全てのAgentがここにアクセスします。

- **Vector Database（長期記憶・ナレッジ）:**
    - 「過去の類似プロジェクトでは何が成功したか？」
    - 「我が社のトーン＆マナー（らしさ）は？」
- **Context Store（短期記憶・文脈）:**
    - 「今の会議で何が決まったか？」
    - 「現在進行中のタスクの状態は？」
- **KPI Store（評価基準）:**
    - 現在のスコアと目標値のギャップ。

### 3. 処理層：階層的意思決定（Hierarchical Processing）

ここを「戦略」と「実行」に分離します。

- **上位レイヤー：Strategy Agent（戦略策定）**
    - **役割:** KPIと記憶を参照し、「何をするべきか（WHAT）」を決定する。
    - **入力:** 「売上が5%低下している」
    - **思考:** 「過去のデータでは、記事数を増やすよりリライトが効果的だった」
    - **出力:** 実行部隊への具体的な指示書（プロンプト）の発行。
- **下位レイヤー：Execution Agent（実務実行）**
    - **役割:** 指示に基づき、手を動かす（HOW）。
    - **入力:** 「記事のリライト指示書」
    - **出力:** 実際のドキュメント、コード、メール下書き。

### 4. 評価層：二重フィードバック（Dual Feedback Loop）

ここが品質担保と「教育」の肝になります。

- **Step 1: AI Critic（自己修正）**
    - 実行AIが作った成果物を、別の「評価用AI」がチェックします。
    - 基準：誤字脱字、論理矛盾、ガイドライン違反。
    - *NGなら実行AIに差し戻し（自律ループ）。*
- **Step 2: Human-in-the-Loop（人間の評価）**
    - AI Criticを通過したものだけを人間が確認します。
    - **Action:** 承認（Go） / 修正指示 / 却下。
    - **Learning:** 人間の「修正指示」自体が、次の学習データとして**中央記憶層**に保存されます。

### 5. 出力層（Output）

- 承認された成果物が、指定のツール（Slack, CMS, Mail, GitHub等）へデプロイされます。

---

### このアーキテクチャのデータフロー例

「KPI（WebサイトのPV）が下がった」というシナリオで流してみます。

1. **入力:** Analyticsツールから「PV前月比90%」というデータが入る。
2. **戦略:** Strategy Agentが**記憶**を参照。「前回はSNS拡散が効いた」と思い出し、「X（Twitter）での要約投稿作成」を指示。
3. **実行:** Execution Agentが過去記事を読み込み、投稿文を作成。
4. **評価1 (AI):** AI Criticがチェック。「文字数が多すぎます。ハッシュタグがありません」→ 自動修正。
5. **評価2 (人):** 人間（あなた）にSlackで通知。「これで投稿しますか？」
    - *人間:* 「もう少し砕けた表現にして」とフィードバック。
6. **学習:** **記憶層**に「この人間は砕けた表現を好む」と追記される。
7. **出力:** 修正版がXに投稿される。