# Neural Organization とツール群の接続設計

## 論点

Neural Organization が現実世界のツール群から組織の状態を知覚するために、どのようなツール群とどのように接続し、どのような情報を取得・統合するべきか。

## 設計思想の前提

### 知覚とは何か

Neural Organization における「知覚（Perception）」とは、組織の現実を捉えることである。組織の現実は、以下の 4 つの次元で構成される：

| 次元 | 内容 | 例 |
|---|---|---|
| **状態（State）** | 組織の現在の状態 | 売上、顧客数、在庫、人員配置 |
| **活動（Activity）** | 組織内で起きている行動 | 商談、開発、カスタマーサポート、採用面接 |
| **関係（Relationship）** | エンティティ間の関係性 | 顧客との関係、チーム間の協働、競合との力関係 |
| **変化（Change）** | 状態・活動・関係の時系列的変化 | トレンド、異常、パターンの変化 |

従来の組織では、これらの情報は「人間の頭の中」「会議での報告」「個別のダッシュボード」に分散して存在し、統合されていない。Neural Organization はこれらを単一の世界モデルに統合する。

### ツール統合の原則

**原則 1: データソースは組織の神経系である**

組織が使うツール群は、組織の活動を記録する「神経系」である。Neural Organization はこれらのツールに接続することで、組織の現実をリアルタイムに知覚する。

**原則 2: 接続は段階的かつ能動的である**

すべてのツールに一度に接続するのではなく、必要性に応じて段階的に接続する。そして、システム自身が「次に何に接続すべきか」を判断する。

**原則 3: 情報の粒度と鮮度はトレードオフである**

すべての情報をリアルタイムで取得する必要はない。情報の重要性と変化速度に応じて、取得頻度を動的に調整する。

**原則 4: ツールは手段であり、目的ではない**

特定のツール（Slack, Salesforce など）への依存を設計の中心に置かない。ツールは入れ替わるが、組織が知覚すべき「現実の次元」は不変である。

## ツール群の分類と接続設計

### カテゴリ 1: コミュニケーション（組織の会話）

**目的**: 組織内の意思決定・問題・合意・温度感を知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| Slack, Microsoft Teams | チャンネル別の会話、メンション、リアクション、スレッドの文脈 | Webhook（新規メッセージ）+ API（履歴取得） | リアルタイム + 日次バッチ |
| Gmail, Outlook | メールの送受信、件名、本文、添付ファイル、スレッド | API（OAuth2） | 時間ごと |
| Zoom, Google Meet | 会議の録画・文字起こし、参加者、頻度 | API + 録画アップロード | 会議後 |
| Notion, Confluence | ドキュメント、更新履歴、コメント | API + Webhook | 更新時 + 日次 |

**取得すべきシグナル**:
- 意思決定の記録（「〜に決めた」「〜で進める」）
- 問題の表出（「〜がうまくいっていない」「〜が課題」）
- 感情の温度感（リアクション、トーン、頻度の変化）
- 暗黙の合意（繰り返されるパターン、言及されないトピック）

**正規化**:
- すべての会話を `Conversation` エンティティに統合
- 参加者、タイムスタンプ、トピック、感情トーン、意思決定の有無を構造化
- 会話の「文脈」を保持（スレッド、引用、返信の関係）

### カテゴリ 2: 顧客関係（組織と市場の接点）

**目的**: 顧客の状態、ニーズ、行動、関係性を知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| Salesforce, HubSpot | 商談、アカウント、コンタクト、活動履歴 | API（REST） | 時間ごと |
| Zendesk, Intercom | サポートチケット、チャット履歴、満足度 | Webhook + API | リアルタイム + 時間ごと |
| Stripe, PayPal | 取引、請求、解約、MRR | Webhook + API | リアルタイム |
| Google Analytics, Mixpanel | プロダクト利用状況、ユーザー行動 | API | 日次 |
| NPS/CSAT ツール | 顧客満足度、フィードバック | API | 回答時 + 週次 |

**取得すべきシグナル**:
- 顧客の健全性（利用頻度、エンゲージメント、支払い状況）
- 解約リスク（利用減少、サポート増加、NPS 低下）
- 拡大機会（利用増加、追加機能への関心）
- 顧客の声（フィードバック、要望、不満）

**正規化**:
- すべての顧客情報を `Customer` エンティティに統合
- 顧客ごとの「健全性スコア」「関係性の歴史」「現在の状態」を構造化
- 顧客の行動（購入、利用、問い合わせ）を時系列イベントとして保持

### カテゴリ 3: プロダクト開発（組織の創造活動）

**目的**: プロダクトの状態、開発活動、品質、技術的負債を知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| GitHub, GitLab | コミット、プルリクエスト、Issue、レビュー | Webhook + API | リアルタイム + 日次 |
| Jira, Linear | タスク、スプリント、バーンダウン、優先度 | Webhook + API | リアルタイム + 時間ごと |
| Figma, Sketch | デザインファイル、コメント、バージョン | API | 更新時 + 週次 |
| Datadog, Sentry | エラー、パフォーマンス、アラート | Webhook + API | リアルタイム |
| CI/CD（CircleCI, GitHub Actions） | ビルド、デプロイ、テスト結果 | Webhook | リアルタイム |

**取得すべきシグナル**:
- 開発速度（コミット頻度、PR のリードタイム、デプロイ頻度）
- 品質の状態（バグ発生率、テストカバレッジ、エラー率）
- 技術的負債（古いコード、未解決 Issue、レビュー待ち PR）
- チームのボトルネック（レビュー遅延、ブロッカー、依存関係）

**正規化**:
- すべての開発活動を `DevelopmentActivity` として時系列化
- コードベースの「健全性」を構造化（品質、負債、リスク）
- 開発チームの「状態」を可視化（キャパシティ、ボトルネック）

### カテゴリ 4: マーケティング（組織の発信）

**目的**: マーケティング活動の効果、リード獲得、ブランド認知を知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| Google Ads, Facebook Ads | キャンペーン、インプレッション、クリック、コンバージョン | API | 日次 |
| Mailchimp, SendGrid | メール配信、開封率、クリック率 | API + Webhook | 配信時 + 日次 |
| SEMrush, Ahrefs | SEO ランキング、バックリンク、競合分析 | API | 週次 |
| Twitter, LinkedIn | ソーシャルメディア投稿、エンゲージメント | API | 日次 |
| Google Search Console | 検索クエリ、表示回数、クリック率 | API | 日次 |

**取得すべきシグナル**:
- チャネル別の効果（ROI、コンバージョン率、獲得コスト）
- コンテンツの反響（エンゲージメント、シェア、言及）
- ブランド認知の変化（検索ボリューム、メディア露出）
- 競合の動向（競合の施策、市場シェアの変化）

**正規化**:
- すべてのマーケティング活動を `MarketingCampaign` として統合
- チャネル別の「効果」を統一的に測定（ROAS, CAC, LTV）
- マーケットの「状態」を構造化（需要、競合、トレンド）

### カテゴリ 5: 人事組織（組織の内部状態）

**目的**: 人員の状態、組織の健全性、採用活動を知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| BambooHR, Workday | 従業員情報、組織図、在籍状況 | API | 日次 |
| Greenhouse, Lever | 採用パイプライン、候補者、面接 | API + Webhook | 時間ごと |
| Culture Amp, Officevibe | エンゲージメント調査、フィードバック | API | 調査時 + 週次 |
| Slack（eNPS bot） | 組織の温度感、eNPS | Custom Integration | 週次 |
| Google Calendar | 1on1、会議の頻度、時間配分 | API | 日次 |

**取得すべきシグナル**:
- 組織の健全性（エンゲージメント、離職率、eNPS）
- 人員の状態（稼働率、バーンアウトリスク、成長）
- 採用の進捗（パイプライン、通過率、オファー承諾率）
- チーム間の協働（会議の頻度、コミュニケーションの偏り）

**正規化**:
- すべての人員情報を `Employee` エンティティに統合
- 組織の「健全性スコア」を構造化（エンゲージメント、離職リスク）
- 採用活動を `RecruitmentPipeline` として時系列化

### カテゴリ 6: ファイナンス（組織の資源状態）

**目的**: 資金の流れ、予算の消化、財務の健全性を知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| QuickBooks, Xero | 収支、請求、支払い、キャッシュフロー | API | 日次 |
| Stripe, PayPal | 売上、手数料、返金 | Webhook + API | リアルタイム |
| Expensify, Concur | 経費申請、承認、カテゴリ | API | 日次 |
| Carta, Pulley | エクイティ、株主構成 | API | 月次 |
| 銀行 API（Plaid） | 残高、取引履歴 | API | 日次 |

**取得すべきシグナル**:
- キャッシュフローの状態（収入、支出、残高、runway）
- 予算の消化状況（部門別、カテゴリ別）
- 収益の健全性（MRR、成長率、チャーン）
- 財務リスク（支払い遅延、異常な支出）

**正規化**:
- すべての財務取引を `FinancialTransaction` として時系列化
- 組織の「財務健全性」を構造化（キャッシュ、収益性、成長）
- 予算を `Budget` エンティティとして管理し、実績と比較

### カテゴリ 7: 運用・インフラ（組織のシステム基盤）

**目的**: システムの稼働状態、パフォーマンス、インシデントを知覚する

| ツール例 | 取得すべき情報 | 接続方法 | 取得頻度 |
|---|---|---|---|
| AWS, GCP, Azure | インスタンス、コスト、リソース使用率 | API | 時間ごと |
| Datadog, New Relic | メトリクス、ログ、トレース | Webhook + API | リアルタイム |
| PagerDuty, Opsgenie | インシデント、アラート、対応状況 | Webhook + API | リアルタイム |
| Terraform, CloudFormation | インフラ構成、変更履歴 | Git Integration | コミット時 |

**取得すべきシグナル**:
- システムの健全性（稼働率、レスポンス時間、エラー率）
- リソースの効率（コスト、使用率、無駄）
- インシデントの状況（頻度、影響範囲、復旧時間）
- インフラの変更（デプロイ、設定変更、スケーリング）

**正規化**:
- すべてのインフライベントを `InfrastructureEvent` として時系列化
- システムの「健全性」を構造化（稼働率、パフォーマンス、コスト）
- インシデントを `Incident` エンティティとして管理し、影響と対応を記録

## 接続方法の設計

### パターン 1: Webhook（イベント駆動）

**適用場面**: リアルタイム性が重要で、変更が発生したときに即座に知覚する必要がある情報

**例**:
- Slack の新規メッセージ
- Salesforce の商談ステージ変更
- GitHub の PR マージ
- Stripe の支払い完了
- PagerDuty のアラート発火

**実装**:
```
外部ツール → Webhook エンドポイント → Event Queue → Perception Layer
```

**利点**: リアルタイム、サーバー負荷が低い
**欠点**: Webhook の信頼性（失敗時の再送、順序保証）に依存

### パターン 2: API Polling（定期取得）

**適用場面**: リアルタイム性が不要で、定期的に状態を同期すれば十分な情報

**例**:
- Google Analytics の日次レポート
- BambooHR の従業員マスタ
- QuickBooks の財務データ
- Ahrefs の SEO データ

**実装**:
```
Scheduler → API Client → 差分検出 → Perception Layer
```

**頻度の決定原則**:
- 高頻度（分単位）: 意思決定に直接影響し、変化が速い（商談、サポートチケット）
- 中頻度（時間単位）: 変化は速いが即時性は不要（GitHub Issue、メール）
- 低頻度（日次・週次）: 変化が遅く、トレンド把握が目的（分析データ、財務）

**利点**: 実装がシンプル、失敗時のリトライが容易
**欠点**: リアルタイム性がない、API レート制限

### パターン 3: Stream Processing（継続的ストリーム）

**適用場面**: 大量のイベントを継続的に処理する必要がある情報

**例**:
- プロダクト利用ログ（クリックストリーム）
- システムメトリクス（CPU、メモリ、ネットワーク）
- IoT センサーデータ（将来的に物理空間を扱う場合）

**実装**:
```
ツール → Kafka/Kinesis → Stream Processor → Perception Layer
```

**利点**: 大量データを効率的に処理、リアルタイム分析が可能
**欠点**: インフラの複雑性が高い

### パターン 4: Human Input（人間からの入力）

**適用場面**: ツールに記録されていない、人間の主観的な情報

**例**:
- 顧客との会話で得た「空気感」（Sensemaker の役割）
- 市場で感じた「違和感」
- 組織内の「暗黙の緊張」

**実装**:
```
人間 → Conversational Interface → 構造化 → Perception Layer
```

**重要性**: これは最も価値の高い Input の一つである。ツールは「記録された事実」しか捉えられないが、人間は「記録されない現実」を知覚できる。

## 情報の正規化と統合

### 正規化の原則

**原則 1: ツール固有の概念を抽象化する**

Salesforce の "Opportunity" も HubSpot の "Deal" も、Neural Organization においては `Deal` という共通エンティティに正規化する。ツールが変わっても、世界モデルは影響を受けない。

**原則 2: 時間を第一級市民として扱う**

すべての情報は「いつ発生したか」「いつ観測されたか」を持つ。これにより、因果関係の推論と時系列分析が可能になる。

**原則 3: 関係性を明示的に保持する**

情報は孤立したレコードではなく、関係性のグラフとして保持する。「この顧客」「この商談」「この担当者」「このプロダクト」が相互にどう関連しているかを明示する。

### 共通エンティティモデル

すべてのツールから取得した情報は、以下の共通エンティティに正規化される：

| エンティティ | 説明 | 主な属性 |
|---|---|---|
| `Customer` | 顧客・見込み客 | ID, 名前, 状態, 健全性スコア, 関係履歴 |
| `Deal` | 商談・取引機会 | ID, 顧客, 金額, ステージ, 確度, 履歴 |
| `Product` | プロダクト・機能 | ID, 名前, 状態, 利用状況, 品質指標 |
| `Employee` | 従業員・チームメンバー | ID, 名前, 役割, 稼働状態, スキル |
| `Task` | タスク・Issue | ID, 担当, 状態, 優先度, 依存関係 |
| `Conversation` | 会話・コミュニケーション | ID, 参加者, トピック, 感情, 意思決定 |
| `Incident` | インシデント・問題 | ID, 重要度, 影響範囲, 対応状況 |
| `Campaign` | マーケティング施策 | ID, チャネル, 予算, 効果, ROI |
| `Transaction` | 財務取引 | ID, 金額, カテゴリ, 相手先, 日時 |
| `Event` | イベント・変化 | ID, 種類, エンティティ, 時刻, 文脈 |

これらのエンティティは相互に関連し、グラフ構造を形成する。これが Layer 1（Understanding）における「世界モデル」の実体である。

## 能動的接続判断のメカニズム

### なぜ能動的である必要があるか

従来のシステムは「あらかじめ定義された接続」しか持たない。Neural Organization は「必要に応じて新たな接続を自ら判断する」。

**例**:
- Reflection が「顧客の解約理由が不明確」という盲点を検出
- → Perception が「解約顧客へのインタビュー記録」への接続を提案
- → 人間が承認し、Zoom 録画や Notion ドキュメントへの接続を追加

### 接続判断のトリガー

| トリガー | 説明 | 例 |
|---|---|---|
| **初期セットアップ** | 組織が Neural Organization を導入する際、基本的なツール群に接続 | Slack, Salesforce, GitHub を最初に接続 |
| **盲点の検出** | Reflection が「知覚していない領域」を検出 | 「顧客の利用状況は見えるが、サポート品質が見えない」→ Zendesk 接続 |
| **人間の要求** | Governor や Sensemaker が新たな情報源を指摘 | 「競合の動向を把握したい」→ SEMrush 接続 |
| **新ツール導入** | 組織が新しいツールを採用 | Linear を導入 → 自動的に接続を提案 |
| **情報の劣化** | 既存の情報源が不十分になった | Slack の重要な議論が減少 → Notion への接続を提案 |

### 接続の優先順位付け

すべてのツールに同時に接続するのは非現実的かつ不要である。接続の優先度は以下の基準で判断される：

**優先度 = （情報の価値） × （盲点の深刻度） / （接続コスト）**

| 要素 | 説明 |
|---|---|
| 情報の価値 | その情報が意思決定にどれだけ影響するか |
| 盲点の深刻度 | その情報がないことで、どれだけの判断ミスが起きているか |
| 接続コスト | API の利用料金、実装工数、メンテナンスコスト |

## 実装時の段階的展開

### Phase 1: Core Perception（コア知覚）

最初に接続すべき「組織の現実を捉える最小限のツール群」

- **コミュニケーション**: Slack（組織の会話）
- **顧客**: Salesforce または HubSpot（顧客との関係）
- **プロダクト**: GitHub（開発活動）
- **人間の入力**: Conversational Interface（Sensemaker からの情報）

これだけで、組織の「現在何が起きているか」の 60-70% が知覚可能になる。

### Phase 2: Extended Perception（拡張知覚）

組織の特性に応じて、追加のツール群に接続

- CS 重視の組織 → Zendesk, Intercom
- マーケ重視の組織 → Google Ads, Mailchimp
- エンジニアリング重視の組織 → Datadog, Sentry

### Phase 3: Deep Perception（深層知覚）

より細かい情報や、高度な分析に必要な情報源に接続

- 財務データ（QuickBooks）
- 人事データ（BambooHR）
- 市場データ（SEMrush）

### Phase 4: Autonomous Perception（自律知覚）

システムが自ら新たな情報源を発見し、接続を提案する

## まとめ

Neural Organization の Perception レイヤーは、組織が使う多様なツール群を「組織の神経系」として統合する。

**設計の核心**:
1. **段階的接続**: すべてに一度に接続するのではなく、必要性に応じて段階的に
2. **能動的判断**: システム自身が「次に何を知覚すべきか」を判断する
3. **ツール非依存**: 特定ツールに依存せず、共通エンティティモデルで抽象化
4. **人間との協働**: ツールが捉えられない「主観的現実」を人間が補完

この設計により、Neural Organization は組織の現実を深く・正確に・継続的に知覚し、Layer 1（Understanding）における世界モデル構築の基盤となる。
